(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[823],{1641:function(e,n,t){(window.__NEXT_P=window.__NEXT_P||[]).push(["/models/flan",function(){return t(7353)}])},7178:function(e,n,t){"use strict";t.d(n,{w:function(){return o}});var i=t(5893),a=t(6010),s=t(5675),r=t.n(s);function o(e){let{src:n,alt:t,full:s}=e;return(0,i.jsx)("div",{className:(0,a.Z)("mt-6 -mb-4 flex justify-center overflow-hidden rounded-xl border dark:border-zinc-800",s?"bg-white":"bg-zinc-100"),children:(0,i.jsx)(r(),{src:n,alt:t,className:(0,a.Z)("w-auto select-none bg-white",s?"":"ring-1 ring-gray-200")})})}},9369:function(e,n,t){"use strict";var i=t(5893);t(7294);var a=t(5391);let s={logo:(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 206 246",fill:"none",children:[(0,i.jsx)("circle",{cx:"40",cy:"40",r:"40",fill:"currentColor"}),(0,i.jsx)("circle",{cx:"40",cy:"206",r:"40",fill:"currentColor"}),(0,i.jsx)("circle",{cx:"166",cy:"120",r:"40",fill:"currentColor"})]}),(0,i.jsx)("span",{style:{marginLeft:".4em",fontWeight:800},children:"Prompt Engineering Guide"})]}),head:function(){let{title:e}=(0,a.ZR)();return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)("title",{children:[e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"," "]}),(0,i.jsx)("meta",{name:"viewport",content:"width=device-width, initial-scale=1.0"}),(0,i.jsx)("meta",{property:"og:title",content:"Prompt Engineering Guide"}),(0,i.jsx)("meta",{property:"og:description",content:"A Comprehensive Overview of Prompt Engineering"}),(0,i.jsx)("meta",{name:"og:title",content:e?e+" | Prompt Engineering Guide":"Prompt Engineering Guide"}),(0,i.jsx)("link",{rel:"icon",href:"/144-favicon.svg",type:"image/svg+xml"}),(0,i.jsx)("link",{rel:"icon",href:"/144-favicon-dark.svg",type:"image/svg+xml",media:"(prefers-color-scheme: dark)"})]})},project:{link:"https://github.com/dair-ai/Prompt-Engineering-Guide"},chat:{link:"https://discord.gg/SKgkVT8BGJ"},docsRepositoryBase:"https://github.com/dair-ai/Prompt-Engineering-Guide/tree/main/",footer:{text:"Copyright \xa9 2023 DAIR.AI"}};n.Z=s},7353:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return j}});var i=t(5893),a=t(8863),s=t(5391),r=t(9369);t(9966);var o=t(1151);t(5675);var d=t(7178),g={src:"/Prompt-Engineering-Guide/_next/static/media/flan-1.c26df985.png",height:507,width:940,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAECAIAAAA8r+mnAAAAaUlEQVR42g3MSQqAIBQAUO9/p1YRtGqyAovUskGk32DYgIG1e6uHdnNndMRcLto45zbznPb9gVQ3RV5YBqkcJvtaguvCj1chESjVVmSgfAGYAUbBSRILRtFx6bLPix4ft/4HJpuURVTVH/oBVkaCL0fpAAAAAElFTkSuQmCC",blurWidth:8,blurHeight:4},l={src:"/Prompt-Engineering-Guide/_next/static/media/flan-2.10409595.png",height:376,width:867,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAADCAIAAAAhqtkfAAAAO0lEQVR42hWLQQ4AIQjE/P9zXaIdhpDFQ3tql0R3Q9stKV0D8tp7Q48yFRFOvyS9qgqI+O69swrOOcAPRnlGBl0y3MIAAAAASUVORK5CYII=",blurWidth:8,blurHeight:3},c={src:"/Prompt-Engineering-Guide/_next/static/media/flan-3.db3a0ec9.png",height:500,width:811,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAIAAAD38zoCAAAAVUlEQVR42h2MSRIAIQwC8//fumQT1InTB4oDtACICFVdmSS9iDB3MbMN+lTyLUCmB9eSMYargrj31i/ND16XLFYCIFlZQvzIOWdO7b2XfAN1aq1FxAd+RXSe+SxRUAAAAABJRU5ErkJggg==",blurWidth:8,blurHeight:5},A={src:"/Prompt-Engineering-Guide/_next/static/media/flan-4.a595d5a6.png",height:377,width:814,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAECAMAAACEE47CAAAAM1BMVEX9/f37+/v6+vr5+vn5+fn4+Pj39/f29vb09fT09PTz8/Py8vLx8fHv8O/u7u7p6eno6OiBxzfzAAAAJ0lEQVR42gVAARIAEAhbMxSF/7/WYZKZVQv7mJpMiNcpgogbHkP+ARBFAN4Pn1uoAAAAAElFTkSuQmCC",blurWidth:8,blurHeight:4},h={src:"/Prompt-Engineering-Guide/_next/static/media/flan-5.98a6c013.png",height:604,width:954,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAIAAAD38zoCAAAAYklEQVR42gUACQ7CIIz/P1McMmrtxboFKDEJyUpjNcf8uhDNpH4/YpwAKR8nscJxcAMRrlBZKBGRqrp7J3rcxxgRsdZKDSgXUL3gnX+1WteGp3ZJZtq7PffdShGROefeOyL+W19wuygsro4AAAAASUVORK5CYII=",blurWidth:8,blurHeight:5},u={src:"/Prompt-Engineering-Guide/_next/static/media/flan-6.a24343d8.png",height:538,width:599,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAHCAIAAAC6O5sJAAAAj0lEQVR42k2Myw6DIBRE+f+f6r514ao1Nk2aYnyAgICXlwK1dONZzGJOZlBKKecslSaEcM6dc6mA/kJITenMGFsWmWI8mp+w1uYTiwJjPfLeA0Auu46IFez1jsdZIjDGOTsxNQtVP4duZFWDCVfIhxC3UD1w+x7qtnt9+sutoUKj4yHu+0S5Xk1JwP3ow/YF6yiesVw+ygoAAAAASUVORK5CYII=",blurWidth:8,blurHeight:7},p={src:"/Prompt-Engineering-Guide/_next/static/media/flan-7.c600a1de.png",height:446,width:947,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAECAIAAAA8r+mnAAAAVklEQVR42g3HWw6DMAwEwNz/nCARpS1xsuuHKA7M35Szo/0wBj/7Lq1RIejqLFQHg6AcB7uYKY0eXmSwD51g3bZvrcCETg8rmbnWCrd59lC9rv/bvPMBwR5bkGNNX9AAAAAASUVORK5CYII=",blurWidth:8,blurHeight:4},m={src:"/Prompt-Engineering-Guide/_next/static/media/flan-8.fda963af.png",height:593,width:935,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAIAAAD38zoCAAAAe0lEQVR42iXM0QqCMBSA4b3/G0VQEdTFQAdZtLWpa1vHHY+d0uo+Qfhv/080iVzoXRx6/iJx7Kij1/j5CWUum/KwP0kd6pjTulgpX9isRQtG6p00W/s480SqOV6hbMmITAz4XHbiEYf33DRTN+8rZ22KQOhCqGprwh0I/5rQaVAcbK0sAAAAAElFTkSuQmCC",blurWidth:8,blurHeight:5},x={src:"/Prompt-Engineering-Guide/_next/static/media/flan-9.78364907.png",height:521,width:942,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAECAIAAAA8r+mnAAAAYUlEQVR42g3GWw6DIBAAQO5/tzaNaWtSEMTuwj5EWb2Azte4BOQzRhTdLRcOS73f+uG0KRDyJv3ouq0ohRrbae6b6OXp6amohb8Mob4jg5gb0/T4fYbZZ4Kl1nGeYgFUvgDav1WzCaT5agAAAABJRU5ErkJggg==",blurWidth:8,blurHeight:4},f={src:"/Prompt-Engineering-Guide/_next/static/media/flan-10.60080e50.png",height:660,width:955,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAIAAABxZ0isAAAAgUlEQVR42gUA2Q6CMGztto5dkuiLif//ayoJBAsjHDtiYBjnKzcB4DvKJZ+5AYA1Ws0pDcy2c/falat+mJ11vSVY0vRLIwhhjPcU93MFAESlOMnangIwSJqWdTsIEZ01ajv4yxORqS2sSbznLcbgc1F9wKNciFkq/XrEm921LkqKPz+jP3C12xf+AAAAAElFTkSuQmCC",blurWidth:8,blurHeight:6},b={src:"/Prompt-Engineering-Guide/_next/static/media/flan-11.3b3298da.png",height:708,width:978,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAIAAABxZ0isAAAAhUlEQVR42gVA3QqCMBR2Z9/+LKGLLqqLoPd/qSAoaDoLddqZbiF8/555ImqGKZVSmp3j3+iMxTM8Yg5iu/VfA0Uujm13v54vsLrmtJplzWOWEFaA90cNI3wb2hCUBKCllFCiEmSNhkU6HYik5BirUpBdWnhjoLAn9lBNGmatiT9meHWi1n9VMUQoSvzVuwAAAABJRU5ErkJggg==",blurWidth:8,blurHeight:6};function w(e){let n=Object.assign({h1:"h1",h2:"h2",p:"p",a:"a",strong:"strong",ul:"ul",li:"li"},(0,o.ah)(),e.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{children:"Scaling Instruction-Finetuned Language Models"}),"\n","\n",(0,i.jsx)(n.h2,{id:"whats-new",children:"What's new?"}),"\n",(0,i.jsx)(d.w,{src:g,alt:"FLAN1"}),"\n",(0,i.jsxs)(n.p,{children:["Image Source: ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,i.jsxs)(n.p,{children:["This paper explores the benefits scaling ",(0,i.jsx)(n.a,{href:"https://arxiv.org/pdf/2109.01652.pdf",children:"instruction finetuning"})," and how it improves performance on a variety of models (PaLM, T5), prompting setups (zero-shot, few-shot, CoT), and benchmarks (MMLU, TyDiQA). This is explored with the following aspects: scaling the number of tasks (1.8K tasks), scaling model size, and finetuning on chain-of-thought data (9 datasets used)."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Finetuning procedure:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"1.8K tasks were phrased as instructions and used to finetune the model"}),"\n",(0,i.jsx)(n.li,{children:"Uses both with and without exemplars, and with and without CoT"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Finetuning tasks and held out tasks shown below:"}),"\n",(0,i.jsx)(d.w,{src:b,alt:"FLAN11"}),"\n",(0,i.jsx)(n.h2,{id:"capabilities--key-results",children:"Capabilities & Key Results"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Instruction finetuning scales well with the number of tasks and the size of the model; this suggests the need for scaling number of tasks and size of model further"}),"\n",(0,i.jsx)(n.li,{children:"Adding CoT datasets into the finetuning enables good performance on reasoning tasks"}),"\n",(0,i.jsx)(n.li,{children:"Flan-PaLM has improved multilingual abilities; 14.9% improvement on one-shot TyDiQA; 8.1% improvement on arithmetic reasoning in under-represented languages"}),"\n",(0,i.jsx)(n.li,{children:"Plan-PaLM also performs well on open-ended generation questions, which is a good indicator for improved usability"}),"\n",(0,i.jsx)(n.li,{children:"Improves performance across responsible AI (RAI) benchmarks"}),"\n",(0,i.jsx)(n.li,{children:"Flan-T5 instruction tuned models demonstrate strong few-shot capabilities and outperforms public checkpoint such as T5"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"The results when scaling number of finetuning tasks and model size:"})," scaling both the size of the model and the number of finetuning tasks is expected to continue improving performance, although scaling the number of tasks has diminished returns."]}),"\n",(0,i.jsx)(d.w,{src:l,alt:"FLAN2"}),"\n",(0,i.jsxs)(n.p,{children:["Image Source: ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"The results when finetuning with non-CoT and CoT data:"})," Jointly finetuning on non-CoT and CoT data improves performance on both evaluations, compared to finetuning on just one or the other."]}),"\n",(0,i.jsx)(d.w,{src:c,alt:"FLAN3"}),"\n",(0,i.jsxs)(n.p,{children:["Image Source: ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,i.jsx)(n.p,{children:"In addition, self-consistency combined with CoT achieves SoTA results on several benchmarks. CoT + self-consistency also significantly improves results on benchmarks involving math problems (e.g., MGSM, GSM8K)."}),"\n",(0,i.jsx)(d.w,{src:A,alt:"FLAN4"}),"\n",(0,i.jsxs)(n.p,{children:["Image Source: ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,i.jsx)(n.p,{children:'CoT finetuning unlocks zero-shot reasoning, activated by the phrase "let\'s think step-by-step", on BIG-Bench tasks. In general, zero-shot CoT Flan-PaLM outperforms zero-shot CoT PaLM without finetuning.'}),"\n",(0,i.jsx)(d.w,{src:u,alt:"FLAN6"}),"\n",(0,i.jsxs)(n.p,{children:["Image Source: ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,i.jsx)(n.p,{children:"Below are some demonstrations of zero-shot CoT for PaLM and Flan-PaLM in unseen tasks."}),"\n",(0,i.jsx)(d.w,{src:h,alt:"FLAN5"}),"\n",(0,i.jsxs)(n.p,{children:["Image Source: ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,i.jsx)(n.p,{children:"Below are more examples for zero-shot prompting. It shows how the PaLM model struggles with repetitions and not replying to instructions in the zero-shot setting where the Flan-PaLM is able to perform well. Few-shot exemplars can mitigate these errors."}),"\n",(0,i.jsx)(d.w,{src:p,alt:"FLAN7"}),"\n",(0,i.jsxs)(n.p,{children:["Image Source: ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,i.jsx)(n.p,{children:"Below are some examples demonstrating more zero-shot capabilities of the Flan-PALM model on several different types of challenging open-ended questions:"}),"\n",(0,i.jsx)(d.w,{src:m,alt:"FLAN8"}),"\n",(0,i.jsxs)(n.p,{children:["Image Source: ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,i.jsx)(d.w,{src:x,alt:"FLAN9"}),"\n",(0,i.jsxs)(n.p,{children:["Image Source: ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,i.jsx)(d.w,{src:f,alt:"FLAN10"}),"\n",(0,i.jsxs)(n.p,{children:["Image Source: ",(0,i.jsx)(n.a,{href:"https://arxiv.org/abs/2210.11416",children:"Scaling Instruction-Finetuned Language Models"})]}),"\n",(0,i.jsxs)(n.p,{children:["You can try ",(0,i.jsx)(n.a,{href:"https://huggingface.co/google/flan-t5-xxl",children:"Flan-T5 models on the Hugging Face Hub"}),"."]})]})}let k={MDXContent:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:n}=Object.assign({},(0,o.ah)(),e.components);return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(w,{...e})}):w(e)},pageOpts:{filePath:"pages/models/flan.mdx",route:"/models/flan",headings:[{depth:1,value:"Scaling Instruction-Finetuned Language Models",id:"scaling-instruction-finetuned-language-models"},{depth:2,value:"What's new?",id:"whats-new"},{depth:2,value:"Capabilities & Key Results",id:"capabilities--key-results"}],timestamp:1679038425e3,pageMap:[{kind:"Meta",data:{index:"Prompt Engineering",introduction:"Introduction",techniques:"Techniques",applications:"Applications",models:"Models",risks:"Risks & Misuses",papers:"Papers",tools:"Tools",notebooks:"Notebooks",datasets:"Datasets",readings:"Additional Readings",about:{title:"About",type:"page"},contact:{title:"Contact ↗",type:"page",href:"https://twitter.com/dair_ai",newWindow:!0}}},{kind:"MdxPage",name:"about",route:"/about"},{kind:"Folder",name:"applications",route:"/applications",children:[{kind:"Meta",data:{pal:"Program-Aided Language Models",generating:"Generating Data"}},{kind:"MdxPage",name:"generating",route:"/applications/generating"},{kind:"MdxPage",name:"pal",route:"/applications/pal"}]},{kind:"MdxPage",name:"applications",route:"/applications"},{kind:"MdxPage",name:"datasets",route:"/datasets"},{kind:"MdxPage",name:"index",route:"/"},{kind:"Folder",name:"introduction",route:"/introduction",children:[{kind:"Meta",data:{settings:"LLM Settings",basics:"Basics of Prompting",elements:"Prompt Elements",tips:"General Tips for Designing Prompts",examples:"Examples of Prompts"}},{kind:"MdxPage",name:"basics",route:"/introduction/basics"},{kind:"MdxPage",name:"elements",route:"/introduction/elements"},{kind:"MdxPage",name:"examples",route:"/introduction/examples"},{kind:"MdxPage",name:"settings",route:"/introduction/settings"},{kind:"MdxPage",name:"tips",route:"/introduction/tips"}]},{kind:"MdxPage",name:"introduction",route:"/introduction"},{kind:"Folder",name:"models",route:"/models",children:[{kind:"Meta",data:{flan:"Flan",chatgpt:"ChatGPT","gpt-4":"GPT-4"}},{kind:"MdxPage",name:"chatgpt",route:"/models/chatgpt"},{kind:"MdxPage",name:"flan",route:"/models/flan"},{kind:"MdxPage",name:"gpt-4",route:"/models/gpt-4"}]},{kind:"MdxPage",name:"models",route:"/models"},{kind:"MdxPage",name:"notebooks",route:"/notebooks"},{kind:"MdxPage",name:"papers",route:"/papers"},{kind:"MdxPage",name:"readings",route:"/readings"},{kind:"Folder",name:"risks",route:"/risks",children:[{kind:"Meta",data:{adversarial:"Adversarial Prompting",factuality:"Factuality",biases:"Biases"}},{kind:"MdxPage",name:"adversarial",route:"/risks/adversarial"},{kind:"MdxPage",name:"biases",route:"/risks/biases"},{kind:"MdxPage",name:"factuality",route:"/risks/factuality"}]},{kind:"MdxPage",name:"risks",route:"/risks"},{kind:"Folder",name:"techniques",route:"/techniques",children:[{kind:"Meta",data:{zeroshot:"Zero-shot Prompting",fewshot:"Few-shot Prompting",cot:"Chain-of-Thought Prompting",consistency:"Self-Consistency",knowledge:"Generate Knowledge Prompting",ape:"Automatic Prompt Engineer",activeprompt:"Active-Prompt",dsp:"Directional Stimulus Prompting",react:"ReAct",multimodalcot:"Multimodal CoT",graph:"Graph Prompting"}},{kind:"MdxPage",name:"activeprompt",route:"/techniques/activeprompt"},{kind:"MdxPage",name:"ape",route:"/techniques/ape"},{kind:"MdxPage",name:"consistency",route:"/techniques/consistency"},{kind:"MdxPage",name:"cot",route:"/techniques/cot"},{kind:"MdxPage",name:"dsp",route:"/techniques/dsp"},{kind:"MdxPage",name:"fewshot",route:"/techniques/fewshot"},{kind:"MdxPage",name:"graph",route:"/techniques/graph"},{kind:"MdxPage",name:"knowledge",route:"/techniques/knowledge"},{kind:"MdxPage",name:"multimodalcot",route:"/techniques/multimodalcot"},{kind:"MdxPage",name:"react",route:"/techniques/react"},{kind:"MdxPage",name:"zeroshot",route:"/techniques/zeroshot"}]},{kind:"MdxPage",name:"techniques",route:"/techniques"},{kind:"MdxPage",name:"tools",route:"/tools"}],flexsearch:{codeblocks:!0},title:"Scaling Instruction-Finetuned Language Models"},pageNextRoute:"/models/flan",nextraLayout:s.ZP,themeConfig:r.Z};var j=(0,a.j)(k)}},function(e){e.O(0,[256,774,888,179],function(){return e(e.s=1641)}),_N_E=e.O()}]);